{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client\n",
    "import pandas as pd\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# InfluxDB instance details\n",
    "\n",
    "bucket = \"schempp\"\n",
    "org = \"UMA\"\n",
    "token = \"TOKEN_ID\"\n",
    "# Store the URL of your InfluxDB instance\n",
    "url=\"http://IP_ADDRESS:PORT\"\n",
    "\n",
    "client = influxdb_client.InfluxDBClient(url=url,token=token,org=org)\n",
    "\n",
    "#Query delay\n",
    "query_api = client.query_api()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downlink query\n",
    "dl_query = 'from(bucket: \"schempp\")\\\n",
    "|> range(start: 2023-05-01T05:40:00Z, stop: 2023-05-01T12:10:00Z)\\\n",
    "|> filter(fn: (r) => r[\"parameter\"] == \"dlMaxRetxThreshold\" or r[\"parameter\"] == \"dlPollByte\" or r[\"parameter\"] == \"dlPollPDU\" or r[\"parameter\"] == \"dlTPollRetr\" or r[\"parameter\"] == \"dlTProhib\" or r[\"parameter\"] == \"dlTReassembly\")\\\n",
    "|> sort()\\\n",
    "|> yield(name: \"sort\")'\n",
    "\n",
    "df_dl_results = query_api.query_data_frame(query=dl_query)\n",
    "\n",
    "#Uplink query\n",
    "ul_query = 'from(bucket: \"schempp\")\\\n",
    "|> range(start: 2023-05-01T06:10:00Z, stop: 2023-05-01T07:10:00Z)\\\n",
    "|> filter(fn: (r) => r[\"parameter\"] == \"ulMaxRetxThreshold\" or r[\"parameter\"] == \"ulPollByte\" or r[\"parameter\"] == \"ulPollPDU\" or r[\"parameter\"] == \"ulTPollRetr\" or r[\"parameter\"] == \"ulTProhib\" or r[\"parameter\"] == \"ulTReassembly\")\\\n",
    "|> sort()\\\n",
    "|> yield(name: \"sort\")'\n",
    "ul_results = query_api.query_data_frame(query=ul_query)\n",
    "\n",
    "#Delay query\n",
    "query_api = client.query_api()\n",
    "delay_query = 'from(bucket: \"schempp\")\\\n",
    "|> range(start: 2023-05-01T06:10:00Z, stop: 2023-05-01T12:10:00Z)\\\n",
    "|> filter(fn: (r) => r[\"_measurement\"] == \"kpis\")\\\n",
    "|> filter(fn: (r) => r[\"_field\"] == \"delay\")\\\n",
    "|> aggregateWindow(every: 1s, fn: mean, createEmpty: false)\\\n",
    "|> yield(name: \"mean\")'\n",
    "\n",
    "df_delay_result = query_api.query_data_frame(query=delay_query)\n",
    "\n",
    "#Jitter query\n",
    "query_api = client.query_api()\n",
    "jitter_query = 'from(bucket: \"schempp\")\\\n",
    "|> range(start: 2023-05-01T06:10:00Z, stop: 2023-05-01T12:10:00Z)\\\n",
    "|> filter(fn: (r) => r[\"_measurement\"] == \"kpis\")\\\n",
    "|> filter(fn: (r) => r[\"_field\"] == \"jitter\")\\\n",
    "|> aggregateWindow(every: 1s, fn: mean, createEmpty: false)\\\n",
    "|> yield(name: \"mean\")'\n",
    "\n",
    "df_jitter_result = query_api.query_data_frame(query=jitter_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfig(config_df_a, time):\n",
    "    for i in range(len(config_df_a)):\n",
    "        #Previous configuration\n",
    "        if (i < (len(config_df_a)-1)):\n",
    "            time_for = config_df_a.iloc[i]['time'].tz_localize(None)\n",
    "            time_for_next = config_df_a.iloc[i+1]['time'].tz_localize(None)\n",
    "            if ((time_for <= time.tz_localize(None)) and (time_for_next > time.tz_localize(None))):\n",
    "                return config_df_a.iloc[i].T\n",
    "        #Current configuration    \n",
    "        elif (i == len(config_df_a)-1):\n",
    "            time_for = config_df_a.iloc[i]['time'].tz_localize(None)\n",
    "            if (time_for <= time.tz_localize(None)):\n",
    "                return config_df_a.iloc[i].T\n",
    "            #Unexpected behavior\n",
    "            else:\n",
    "                print(\"[ERROR] There is no configuration learned at the time & date provided:\")\n",
    "                print(time.tz_localize(None))\n",
    "                return None\n",
    "\n",
    "\n",
    "def addConfig(configToAppend):\n",
    "    global total_configs_df\n",
    "    if (getConfigID(configToAppend) == -1):\n",
    "        total_configs_df = total_configs_df.append(configToAppend, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Config already exists\")\n",
    "\n",
    "\n",
    "def getConfigID(configToCheck):\n",
    "    global total_configs_df\n",
    "    for i in range(len(total_configs_df)):\n",
    "        if (total_configs_df.iloc[i]['dlMaxRetxThreshold'] == configToCheck['dlMaxRetxThreshold'] and\n",
    "            total_configs_df.iloc[i]['dlPollByte'] == configToCheck['dlPollByte'] and\n",
    "            total_configs_df.iloc[i]['dlPollPDU'] == configToCheck['dlPollPDU'] and\n",
    "            total_configs_df.iloc[i]['dlTPollRetr'] == configToCheck['dlTPollRetr'] and\n",
    "            total_configs_df.iloc[i]['dlTProhib'] == configToCheck['dlTProhib'] and\n",
    "            total_configs_df.iloc[i]['dlTReassembly'] == configToCheck['dlTReassembly']):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "mask_dlMaxRetxThreshold=df_dl_results.loc[:,'parameter'] == \"dlMaxRetxThreshold\"\n",
    "mask_dlPollByte=df_dl_results.loc[:,'parameter'] == \"dlPollByte\"\n",
    "mask_dlPollPDU=df_dl_results.loc[:,'parameter'] == \"dlPollPDU\"\n",
    "mask_dlTPollRetr=df_dl_results.loc[:,'parameter'] == \"dlTPollRetr\"\n",
    "mask_dlTProhib=df_dl_results.loc[:,'parameter'] == \"dlTProhib\"\n",
    "mask_dlTReassembly=df_dl_results.loc[:,'parameter'] == \"dlTReassembly\"\n",
    "\n",
    "df_dl_results = df_dl_results.sort_values(by=['_time'])\n",
    "config_df=pd.DataFrame()\n",
    "config_df=pd.DataFrame()\n",
    "total_configs_df = pd.DataFrame()\n",
    "delay_df=pd.DataFrame()\n",
    "jitter_df=pd.DataFrame()\n",
    "\n",
    "delay_df['delay'] = list(df_delay_result[\"_value\"])\n",
    "delay_df['time'] = df_delay_result[\"_time\"]\n",
    "\n",
    "jitter_df['jitter'] = list(df_jitter_result[\"_value\"])\n",
    "jitter_df['time'] = df_jitter_result[\"_time\"]\n",
    "\n",
    "config_df['dlMaxRetxThreshold'] = list(df_dl_results[mask_dlMaxRetxThreshold][\"_value\"])\n",
    "config_df['dlPollByte'] = list(df_dl_results[mask_dlPollByte][\"_value\"])\n",
    "config_df['dlPollPDU'] = list(df_dl_results[mask_dlPollPDU][\"_value\"])\n",
    "config_df['dlTPollRetr'] = list(df_dl_results[mask_dlTPollRetr][\"_value\"])\n",
    "config_df['dlTProhib'] = list(df_dl_results[mask_dlTProhib][\"_value\"])\n",
    "config_df['dlTReassembly'] = list(df_dl_results[mask_dlTReassembly][\"_value\"])\n",
    "config_df['time'] = list(df_dl_results[mask_dlTReassembly][\"_time\"])\n",
    "\n",
    "merged_inner = pd.merge(left=delay_df, right=jitter_df, left_on='time', right_on='time')\n",
    "config_df_f = config_df.drop_duplicates(subset=config_df.columns.difference(['time']), keep=\"first\")\n",
    "\n",
    "\n",
    "as_df=pd.DataFrame()\n",
    "range_df = pd.DataFrame(columns = [\"start_time\", \"end_time\",\n",
    "                                   \"min_delay\", \"max_delay\", \"mean_delay\", \"median_delay\",\n",
    "                                   \"min_jitter\", \"max_jitter\" , \"mean_jitter\", \"median_jitter\",])\n",
    "\n",
    "\n",
    "as_df = merged_inner\n",
    "columns=['dlMaxRetxThreshold', 'dlPollByte', 'dlPollPDU', 'dlTPollRetr','dlTProhib','dlTReassembly']\n",
    "calc_columns=['min_delay', 'max_delay', 'mean_delay', 'median_delay','min_jitter', 'max_jitter', 'mean_jitter', 'median_jitter']\n",
    "\n",
    "config_df_f = config_df_f.sort_values(by=['time'])\n",
    "\n",
    "for index, row in config_df_f.iterrows():\n",
    "    addConfig(row)\n",
    "\n",
    "# Definimos el tiempo de inicio y fin\n",
    "start_time = as_df['time'].iloc[0]\n",
    "end_time = as_df['time'].iloc[len(as_df)-1]\n",
    "\n",
    "automaton=pd.DataFrame()\n",
    "# Creamos una lista con los tiempos incrementales\n",
    "times = pd.date_range(start_time, end_time, freq='10s')\n",
    "# Creamos el DataFrame con la columna de tiempo\n",
    "automaton = pd.DataFrame({'time': times})\n",
    "\n",
    "\n",
    "for index, row in automaton.iterrows():\n",
    "    if (index < (len(automaton)-1)):\n",
    "            time_for = automaton.iloc[index]['time']\n",
    "            time_for_next = automaton.iloc[index+1]['time']\n",
    "            df_sub = as_df[as_df['time'].between(time_for, time_for_next)]\n",
    "            if (df_sub.empty == False):\n",
    "                new_row = {\"start_time\":time_for,\n",
    "                           \"end_time\":time_for_next,\n",
    "                           'min_delay':df_sub['delay'].min(),\n",
    "                           'max_delay':df_sub['delay'].max(),\n",
    "                           'mean_delay':df_sub['delay'].mean(),\n",
    "                           'median_delay':df_sub['delay'].median(),\n",
    "                           'min_jitter':df_sub['jitter'].min(),\n",
    "                           'max_jitter':df_sub['jitter'].max(),\n",
    "                           'mean_jitter':df_sub['jitter'].mean(),\n",
    "                           'median_jitter':df_sub['jitter'].median(),\n",
    "                           }\n",
    "                range_df = range_df.append(new_row, ignore_index=True)\n",
    "                for column in calc_columns:\n",
    "                    automaton.at[index,column] = new_row[column]\n",
    "\n",
    "            elif (index == len(automaton)-1):\n",
    "                time_for = automaton.iloc[index]['time']\n",
    "                df_sub = as_df[as_df['time'] > time_for]\n",
    "                if (df_sub.empty == False):\n",
    "                    new_row = {\"start_time\":time_for,\n",
    "                            \"end_time\":'',\n",
    "                            'min_delay':df_sub['delay'].min(),\n",
    "                            'max_delay':df_sub['delay'].max(),\n",
    "                            'mean_delay':df_sub['delay'].mean(),\n",
    "                            'median_delay':df_sub['delay'].median(),\n",
    "                            'min_jitter':df_sub['jitter'].min(),\n",
    "                            'max_jitter':df_sub['jitter'].max(),\n",
    "                            'mean_jitter':df_sub['jitter'].mean(),\n",
    "                            'median_jitter':df_sub['jitter'].median(),\n",
    "                            }\n",
    "                    for column in calc_columns:\n",
    "                        automaton.at[index,column] = new_row[column]\n",
    "    \n",
    "\n",
    "for index, row in automaton.iterrows():\n",
    "    configAdd = getConfig(config_df.sort_values(by=['time']), row['time'])\n",
    "    for column in columns:\n",
    "        automaton.at[index,column] = configAdd[column]\n",
    "\n",
    "automaton['profile_id'] = '1'\n",
    "automaton['config_id'] = ''\n",
    "\n",
    "for index, row in automaton.iterrows():\n",
    "    automaton.at[index,'config_id'] = getConfigID(row)\n",
    "\n",
    "automaton_proc = automaton.groupby('config_id').agg({'min_delay': ['min'], 'max_delay': ['max'], 'min_jitter': ['min'], 'max_jitter': ['max']})\n",
    "\n",
    "automaton_proc['config_id'] = automaton_proc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNetworkState(min_delay, max_delay, min_jitter, max_jitter, profile_id, config_id, repetitions):\n",
    "    global automaton_network_states\n",
    "    new_row = {'min_delay':min_delay,\n",
    "               'max_delay':max_delay,\n",
    "               'min_jitter':min_jitter,\n",
    "               'max_jitter':max_jitter,\n",
    "               'profile_id':profile_id,\n",
    "               'config_id':config_id,\n",
    "               'repetitions':repetitions}\n",
    "    automaton_network_states = automaton_network_states.append(new_row, ignore_index=True)\n",
    "\n",
    "def updateNetworkState(min_delay, max_delay, min_jitter, max_jitter, profile_id, config_id, repetitions):\n",
    "    global automaton_network_states\n",
    "    for i in range(len(automaton_network_states)):\n",
    "        if (automaton_network_states.iloc[i]['min_delay'] == min_delay and\n",
    "            automaton_network_states.iloc[i]['max_delay'] == max_delay and\n",
    "            automaton_network_states.iloc[i]['min_jitter'] == min_jitter and\n",
    "            automaton_network_states.iloc[i]['max_jitter'] == max_jitter and\n",
    "            automaton_network_states.iloc[i]['profile_id'] == profile_id and\n",
    "            automaton_network_states.iloc[i]['config_id'] == config_id):\n",
    "            automaton_network_states.at[i,'repetitions'] = automaton_network_states.iloc[i]['repetitions'] + repetitions\n",
    "            return\n",
    "    addNetworkState(min_delay, max_delay, min_jitter, max_jitter, profile_id, config_id, repetitions)\n",
    "\n",
    "\n",
    "def getNetworkStateID(qty, profile_id, config_id):\n",
    "    global automaton_network_states\n",
    "    for i in range(len(automaton_network_states)):\n",
    "        if (automaton_network_states.iloc[i]['qty'] == qty and\n",
    "            automaton_network_states.iloc[i]['profile_id'] == profile_id and\n",
    "            automaton_network_states.iloc[i]['config_id'] == config_id):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def getqtyID(row):\n",
    "    global qty_df\n",
    "    for i in range(len(qty_df)):\n",
    "        if (qty_df.iloc[i]['min_delay'] <= row['max_delay']['max'] and\n",
    "            qty_df.iloc[i]['max_delay'] >= row['max_delay']['max'] and\n",
    "            qty_df.iloc[i]['min_jitter'] <= row['max_jitter']['max'] and\n",
    "            qty_df.iloc[i]['max_jitter'] >= row['max_jitter']['max']):\n",
    "            return qty_df.iloc[i]['qty']\n",
    "    return 0\n",
    "\n",
    "\n",
    "#qty definition\n",
    "data = {'qty': [-18, -15, -5, 1, 2, 3, 4], 'min_delay': [10000000, 0, 10000000, 0, 6000000, 0, 6000000], 'max_delay': [2000000000000, 10000000, 2000000000000, 6000000, 10000000, 6000000, 10000000], 'min_jitter': [0, 10000000, 10000000, 0, 0, 1000000, 1000000], 'max_jitter': [10000000, 2000000000000, 2000000000000, 1000000, 1000000, 10000000, 10000000]}\n",
    "qty_df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "for index, row in automaton_proc.iterrows():\n",
    "    automaton_proc.at[index,'qty'] = getqtyID(row)\n",
    "\n",
    "\n",
    "final_automaton = automaton_proc[['config_id','qty']].reset_index(drop=True)\n",
    "\n",
    "#print(final_automaton)\n",
    "final_automaton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(final_automaton, 'config_id', 'qty')\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(10, 8))\n",
    "nx.draw_shell(G, with_labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
