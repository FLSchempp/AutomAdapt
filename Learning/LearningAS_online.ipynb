{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import subprocess\n",
    "import warnings\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from IPython.display import clear_output\n",
    "from influxdb_client.client.warnings import MissingPivotFunction\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "warnings.simplefilter(\"ignore\", MissingPivotFunction)\n",
    "\n",
    "\n",
    "# InfluxDB instance details\n",
    "bucket = \"schempp\"\n",
    "org = \"UMA\"\n",
    "token = \"TOKEN_ID\"\n",
    "url=\"http://IP_ADDRESS:PORT\"\n",
    "# Create influxDB client connection\n",
    "client = influxdb_client.InfluxDBClient(url=url,token=token,org=org, debug=False)\n",
    "\n",
    "# Query API\n",
    "query_api = client.query_api()\n",
    "\n",
    "# Dataframes creation\n",
    "automaton_df = pd.DataFrame(columns=['configID', 'qtyID', 'transition', 'slapsed_time'])\n",
    "total_configs_df = pd.DataFrame(columns=['dlMaxRetxThreshold', 'dlPollByte', 'dlPollPDU', 'dlTPollRetr', 'dlTProhib', 'dlTReassembly', 'ulMaxRetxThreshold', 'ulPollByte', 'ulPollPDU', 'ulTPollRetr', 'ulTProhib', 'ulTReassembly','id'])\n",
    "reconfigurations_df = pd.DataFrame(columns=['original_configID', 'selected_configID', 'time'])\n",
    "# Variables\n",
    "current_config_id, current_qty_id, current_state_id = (0,)*3\n",
    "old_config_id = 0\n",
    "read_config_id, read_qty_id, read_state_id = (0,)*3\n",
    "time_state = 0\n",
    "config_time = 15\n",
    "current_time = \"\"\n",
    "revisited_state = False\n",
    "\n",
    "# Functions definition\n",
    "\n",
    "def addReconfiguration(original_configID, selected_configID, time):\n",
    "    global reconfigurations_df\n",
    "    reconfigurations_df = reconfigurations_df.append({\"original_configID\":original_configID, \"selected_configID\":selected_configID, \"time\":time}, ignore_index=True)\n",
    "\n",
    "def getqtyID(delay, jitter):\n",
    "    global qty_df\n",
    "    for i in range(len(qty_df)):\n",
    "        if (qty_df.iloc[i]['min_delay'] <= delay and\n",
    "            qty_df.iloc[i]['max_delay'] >= delay and\n",
    "            qty_df.iloc[i]['min_jitter'] <= jitter and\n",
    "            qty_df.iloc[i]['max_jitter'] >= jitter):\n",
    "            return qty_df.iloc[i]['qty']\n",
    "    return 0\n",
    "\n",
    "\n",
    "def addConfig(configParams, configID):\n",
    "    global total_configs_df\n",
    "    global current_config_id\n",
    "    if (configExists(configID) == False):\n",
    "        configToAppend = {\"dlMaxRetxThreshold\":configParams[0], \"dlPollByte\":configParams[1],\n",
    "                            \"dlPollPDU\":configParams[2], \"dlTPollRetr\":configParams[3],\n",
    "                            \"dlTProhib\":configParams[4], \"dlTReassembly\":configParams[5],\n",
    "                            \"ulMaxRetxThreshold\":configParams[6], \"ulPollByte\":configParams[7],\n",
    "                            \"ulPollPDU\":configParams[8], \"ulTPollRetr\":configParams[9],\n",
    "                            \"ulTProhib\":configParams[10], \"ulTReassembly\":configParams[11],\n",
    "                            \"id\":configID}\n",
    "\n",
    "        total_configs_df = total_configs_df.append(configToAppend, ignore_index=True)\n",
    "\n",
    "\n",
    "def getConfigID(configToCheck):\n",
    "    global total_configs_df\n",
    "    for i in range(len(total_configs_df)):\n",
    "        if (total_configs_df.iloc[i]['dlMaxRetxThreshold'] == configToCheck['dlMaxRetxThreshold'] and\n",
    "            total_configs_df.iloc[i]['dlPollByte'] == configToCheck['dlPollByte'] and\n",
    "            total_configs_df.iloc[i]['dlPollPDU'] == configToCheck['dlPollPDU'] and\n",
    "            total_configs_df.iloc[i]['dlTPollRetr'] == configToCheck['dlTPollRetr'] and\n",
    "            total_configs_df.iloc[i]['dlTProhib'] == configToCheck['dlTProhib'] and\n",
    "            total_configs_df.iloc[i]['dlTReassembly'] == configToCheck['dlTReassembly']):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def configExists(configID):\n",
    "    global total_configs_df\n",
    "    for i in range(len(total_configs_df)):\n",
    "        if (total_configs_df.iloc[i]['id'] == configID):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def getConfigParams(configID):\n",
    "    global total_configs_df\n",
    "    for i in range(len(total_configs_df)):\n",
    "        if (total_configs_df.iloc[i]['id'] == configID):\n",
    "            return total_configs_df.iloc[i]\n",
    "    return -1\n",
    "\n",
    "    \n",
    "def manageAutomatonState(readState):\n",
    "    #Global variables\n",
    "    global automaton_df\n",
    "    global current_config_id\n",
    "    global current_qty_id\n",
    "    global current_state_id\n",
    "    global time_state\n",
    "    global revisited_state\n",
    "        \n",
    "    #The automaton is empty\n",
    "    if (automaton_df.empty):\n",
    "        #Add the state to the automaton\n",
    "        automaton_df = automaton_df.append(readState, ignore_index=True)\n",
    "        print(\"First state added to the automaton at \" + current_time + \" (current state: \" + str(current_state_id) + \")\")\n",
    "        #Update the global variables\n",
    "        current_config_id = readState['configID']\n",
    "        current_qty_id = readState['qtyID']\n",
    "        current_state_id = automaton_df.tail(1).index.item()\n",
    "        time_state = 0\n",
    "        return current_state_id\n",
    "    \n",
    "    #The automaton is not empty\n",
    "    else:\n",
    "        #Check if the state is already in the automaton\n",
    "        automaton_index = getIndexAutomatonStateByConfigIDAndQtyID(readState['configID'], readState['qtyID'])\n",
    "\n",
    "        #The state is in the automaton and is not the current state --> add transition type\n",
    "        if (automaton_index != -1 and automaton_index != current_state_id):\n",
    "            if (readState['configID'] != current_config_id and readState['qtyID'] != current_qty_id):\n",
    "                if ((automaton_df.at[current_state_id, 'transition'][0]) == \"\"):\n",
    "                    automaton_df.at[current_state_id, 'transition'][0] = (\"config_qty-\" + str(automaton_index))\n",
    "                else:\n",
    "                    automaton_df.at[current_state_id, 'transition'].append(\"config_qty-\" + str(automaton_index) )\n",
    "            elif (readState['configID'] != current_config_id):\n",
    "                if ((automaton_df.at[current_state_id, 'transition'][0]) == \"\"):\n",
    "                    automaton_df.at[current_state_id, 'transition'][0] = (\"config-\" + str(automaton_index))\n",
    "                else:\n",
    "                    automaton_df.at[current_state_id, 'transition'].append(\"config-\" + str(automaton_index))\n",
    "            elif (readState['qtyID'] != current_qty_id):\n",
    "                if ((automaton_df.at[current_state_id, 'transition'][0]) == \"\"):\n",
    "                    automaton_df.at[current_state_id, 'transition'][0] = (\"qty-\" + str(automaton_index))\n",
    "                else:\n",
    "                    automaton_df.at[current_state_id, 'transition'].append(\"qty-\" + str(automaton_index))\n",
    "            if (automaton_df.at[current_state_id, 'slapsed_time'][0] == 0):\n",
    "                automaton_df.at[current_state_id, 'slapsed_time'][0] = time_state\n",
    "            else:    \n",
    "                automaton_df.at[current_state_id, 'slapsed_time'].append(time_state)\n",
    "            #Update the global variables\n",
    "            current_config_id = readState['configID']\n",
    "            current_qty_id = readState['qtyID']\n",
    "            current_state_id = automaton_index\n",
    "            time_state = 0\n",
    "            revisited_state = True\n",
    "            return current_state_id\n",
    "\n",
    "        elif (automaton_index != -1 and automaton_index == current_state_id):\n",
    "            #Do nothing\n",
    "            return current_state_id\n",
    "\n",
    "        #The state is NOT in the automaton\n",
    "        else:\n",
    "            #Check and add transition type\n",
    "            if (current_config_id != readState['configID'] and current_config_id != readState['qtyID']):\n",
    "                if ((automaton_df.at[current_state_id, 'transition'][0]) == \"\"):\n",
    "                    automaton_df.at[current_state_id, 'transition'][0] = (\"config_qty-\" + str(automaton_df.tail(1).index.item()+1))\n",
    "                else:\n",
    "                    automaton_df.at[current_state_id, 'transition'].append(\"config_qty-\" + str(automaton_df.tail(1).index.item()+1))\n",
    "            elif (current_config_id != readState['configID']):\n",
    "                if ((automaton_df.at[current_state_id, 'transition'][0]) == \"\"):\n",
    "                    automaton_df.at[current_state_id, 'transition'][0] = (\"config-\" + str(automaton_df.tail(1).index.item()+1))\n",
    "                else:\n",
    "                    automaton_df.at[current_state_id, 'transition'].append(\"config-\" + str(automaton_df.tail(1).index.item()+1))\n",
    "            elif (current_config_id != readState['qtyID']):\n",
    "                if ((automaton_df.at[current_state_id, 'transition'][0]) == \"\"):\n",
    "                    automaton_df.at[current_state_id, 'transition'][0] = (\"qty-\" + str(automaton_df.tail(1).index.item()+1))\n",
    "                else:\n",
    "                    automaton_df.at[current_state_id, 'transition'].append(\"qty-\" + str(automaton_df.tail(1).index.item()+1))\n",
    "            if (automaton_df.at[current_state_id, 'slapsed_time'][0] == 0):\n",
    "                automaton_df.at[current_state_id, 'slapsed_time'][0] = time_state\n",
    "            else:    \n",
    "                automaton_df.at[current_state_id, 'slapsed_time'].append(time_state)\n",
    "            #Add the state to the automaton\n",
    "            automaton_df = automaton_df.append(readState, ignore_index=True)\n",
    "            #Update the global variables\n",
    "            current_config_id = readState['configID']\n",
    "            current_qty_id = readState['qtyID']\n",
    "            current_state_id = automaton_df.tail(1).index.item()\n",
    "            print(\"State \" + str(current_state_id) + \" added to the automaton at \" + current_time  + \" (current state: \" + str(current_state_id) + \")\") \n",
    "            time_state = 0\n",
    "            revisited_state = False\n",
    "            return current_state_id\n",
    "    \n",
    "\n",
    "def addSlapsedTimeToState(configID, qtyID, timeToAdd):\n",
    "    global time_state\n",
    "    global automaton_df\n",
    "    for i in range(len(automaton_df)):\n",
    "        if (automaton_df.iloc[i]['configID'] == configID and automaton_df.iloc[i]['qtyID'] == qtyID):\n",
    "            automaton_df.iloc[i]['slapsed_time'] = timeToAdd\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def getAutomatonState(stateID):\n",
    "    global automaton_df\n",
    "    for i in range(len(automaton_df)):\n",
    "        if (automaton_df.iloc[i]['stateID'] == stateID):\n",
    "            return automaton_df.iloc[i]\n",
    "    return -1\n",
    "\n",
    "def getAutomatonStateByConfigID(configID):\n",
    "    global automaton_df\n",
    "    for i in range(len(automaton_df)):\n",
    "        if (automaton_df.iloc[i]['configID'] == configID):\n",
    "            return automaton_df.iloc[i]\n",
    "    return -1\n",
    "\n",
    "def getAutomatonStateByQtyID(qtyID):\n",
    "    global automaton_df\n",
    "    for i in range(len(automaton_df)):\n",
    "        if (automaton_df.iloc[i]['qtyID'] == qtyID):\n",
    "            return automaton_df.iloc[i]\n",
    "    return -1\n",
    "\n",
    "def getAutomatonStateByTransition(transition):\n",
    "    global automaton_df\n",
    "    for i in range(len(automaton_df)):\n",
    "        if (automaton_df.iloc[i]['transition'] == transition):\n",
    "            return automaton_df.iloc[i]\n",
    "    return -1\n",
    "\n",
    "def getAutomatonStateByConfigIDAndQtyID(configID, qtyID):\n",
    "    global automaton_df\n",
    "    for i in range(len(automaton_df)):\n",
    "        if (automaton_df.iloc[i]['configID'] == configID and automaton_df.iloc[i]['qtyID'] == qtyID):\n",
    "            return automaton_df.iloc[i]\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def getIndexAutomatonStateByConfigIDAndQtyID(configID, qtyID):\n",
    "    global automaton_df\n",
    "    for i in range(len(automaton_df)):\n",
    "        if (automaton_df.iloc[i]['configID'] == configID and automaton_df.iloc[i]['qtyID'] == qtyID):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def checkAutomatonStateByConfigIDAndQtyID(configID, qtyID):\n",
    "    global automaton_df\n",
    "    for i in range(len(automaton_df)):\n",
    "        if (automaton_df.iloc[i]['configID'] == configID and automaton_df.iloc[i]['qtyID'] == qtyID):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def getAutomatonStateByConfigIDAndTransition(configID, transition):\n",
    "    global automaton_df\n",
    "    for i in range(len(automaton_df)):\n",
    "        if (automaton_df.iloc[i]['configID'] == configID and automaton_df.iloc[i]['transition'] == transition):\n",
    "            return automaton_df.iloc[i]\n",
    "    return -1\n",
    "\n",
    "def getAutomatonStateByQtyIDAndTransition(qtyID, transition):\n",
    "    global automaton_df\n",
    "    for i in range(len(automaton_df)):\n",
    "        if (automaton_df.iloc[i]['qtyID'] == qtyID and automaton_df.iloc[i]['transition'] == transition):\n",
    "            return automaton_df.iloc[i]\n",
    "    return -1\n",
    "\n",
    "def addSecondQuery(query, secondsToAdd):\n",
    "    start_index = query.index('start:') + 7\n",
    "    stop_index = query.index('stop:') + 6\n",
    "\n",
    "    start_time_str = query[start_index:query.index('Z', start_index)]\n",
    "    stop_time_str = query[stop_index:query.index('Z', stop_index)]\n",
    "\n",
    "    start_time = datetime.fromisoformat(start_time_str)\n",
    "    stop_time = datetime.fromisoformat(stop_time_str)\n",
    "\n",
    "    modified_start_time = (start_time + timedelta(seconds=secondsToAdd)).isoformat()\n",
    "    modified_stop_time = (stop_time + timedelta(seconds=secondsToAdd)).isoformat()\n",
    "\n",
    "    modified_query = query[:start_index] + modified_start_time + query[query.index('Z', start_index):stop_index] + modified_stop_time + query[query.index('Z', stop_index):]\n",
    "\n",
    "    return modified_query\n",
    "\n",
    "def expandQuery(query):\n",
    "    start_index = query.index('start:') + 7\n",
    "    stop_index = query.index('stop:') + 6\n",
    "\n",
    "    start_time_str = query[start_index:query.index('Z', start_index)]\n",
    "    stop_time_str = query[stop_index:query.index('Z', stop_index)]\n",
    "\n",
    "    start_time = datetime.fromisoformat(start_time_str)\n",
    "    stop_time = datetime.fromisoformat(stop_time_str)\n",
    "\n",
    "    modified_start_time = (start_time - timedelta(seconds=1)).isoformat()\n",
    "    modified_stop_time = (stop_time + timedelta(seconds=1)).isoformat()\n",
    "\n",
    "    modified_query = query[:start_index] + modified_start_time + query[query.index('Z', start_index):stop_index] + modified_stop_time + query[query.index('Z', stop_index):]\n",
    "\n",
    "    return modified_query\n",
    "\n",
    "def getStateSlapsedTime(state_index):\n",
    "    global automaton_df\n",
    "    times = []\n",
    "    if (automaton_df.empty == False):\n",
    "        for i in range(len(automaton_df.iloc[state_index]['transition'])):\n",
    "            if (automaton_df.iloc[state_index]['transition'][i].startswith(\"qty\")):\n",
    "                times.append(automaton_df.iloc[state_index]['slapsed_time'][i])\n",
    "    return times\n",
    "\n",
    "def predictionDetected(qty_objective, read_qty_id, goal_time):\n",
    "    global config_time\n",
    "    global time_state\n",
    "    global current_state_id\n",
    "    global current_qty_id\n",
    "    global revisited_state\n",
    "    slapsed_times_list = getStateSlapsedTime(current_state_id)\n",
    "\n",
    "    if (revisited_state == True and len(slapsed_times_list) > 0):\n",
    "        min_slapsed_time = min([x for x in getStateSlapsedTime(current_state_id)])\n",
    "        if (min_slapsed_time > goal_time):\n",
    "            revisited_state = False\n",
    "            return True\n",
    "    else:   \n",
    "        return False\n",
    "    \n",
    "def getSuitableConfigurations(qty_objective, goal_time):\n",
    "    global automaton_df\n",
    "    global total_configs_df\n",
    "    suitable_configs = []\n",
    "\n",
    "    #Filter automaton_df by qtyID\n",
    "    automaton_df_qty_obj = automaton_df[automaton_df['qtyID'] == qty_objective]\n",
    "    #Sum slapsed_time values\n",
    "    automaton_df_qty_obj['sum_slapsed_time'] = automaton_df_qty_obj['slapsed_time'].apply(lambda x: sum(x))\n",
    "    #Sort by sum_slapsed_time\n",
    "    automaton_df_qty_obj.sort_values(by=['sum_slapsed_time'], inplace=True, ascending=False)\n",
    "    \n",
    "    for i in range(len(automaton_df_qty_obj)):\n",
    "        if ((automaton_df_qty_obj.iloc[i]['sum_slapsed_time'].min()) >= goal_time):\n",
    "            suitable_configs.append(getConfigParams(automaton_df_qty_obj.iloc[i]['configID']))\n",
    "    return suitable_configs\n",
    "\n",
    "def networkReconfiguration(selectedConfig):\n",
    "    global old_config_id\n",
    "    print(\"Network reconfiguration started (ETA: 40 seconds)\")\n",
    "    subprocess.call([\"/home/schempp/Documents/NokiaAdminCLI/setConfigMicroArguments.sh\", selectedConfig[0], selectedConfig[1], selectedConfig[2], selectedConfig[3], selectedConfig[4], selectedConfig[5], selectedConfig[6], selectedConfig[7], selectedConfig[8], selectedConfig[9], selectedConfig[10], selectedConfig[11]])\n",
    "    subprocess.call([\"/home/schempp/Documents/NokiaAdminCLI/telit_reconnection.sh\"])\n",
    "    if (len(selectedConfig) == 13):\n",
    "        addReconfiguration(old_config_id, selectedConfig[12], datetime.utcnow().isoformat())\n",
    "        old_config_id = selectedConfig[12]\n",
    "    else:\n",
    "        old_config_id = getConfigIDhash(selectedConfig)\n",
    "    print(\"Network reconfiguration completed\")\n",
    "    return True\n",
    "\n",
    "def getConfigIDhash(config):\n",
    "    return hashlib.sha256(''.join(config).encode('utf-8')).hexdigest()\n",
    "\n",
    "def reconfigAlreadyTested(configID):\n",
    "    global reconfigurations_df\n",
    "    if (reconfigurations_df.empty == False):\n",
    "        if (configID in reconfigurations_df['original_configID'].values):\n",
    "            print(\"Selected config (\" + configID + \") already tested\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def insertIntervalConfigQuery(interval_time_to_add):\n",
    "    first_part = 'from(bucket: \"schempp\")|> range(start: -'\n",
    "    second_part = 's)|> filter(fn: (r) => r[\"parameter\"] == \"dlMaxRetxThreshold\" or r[\"parameter\"] == \"dlPollByte\" or r[\"parameter\"] == \"dlPollPDU\" or r[\"parameter\"] == \"dlTPollRetr\" or r[\"parameter\"] == \"dlTProhib\" or r[\"parameter\"] == \"dlTReassembly\" or r[\"parameter\"] == \"ulMaxRetxThreshold\" or r[\"parameter\"] == \"ulPollByte\" or r[\"parameter\"] == \"ulPollPDU\" or r[\"parameter\"] == \"ulTPollRetr\" or r[\"parameter\"] == \"ulTProhib\" or r[\"parameter\"] == \"ulTReassembly\")|> sort()|> yield(name: \"sort\")'\n",
    "    return first_part + str(interval_time_to_add) + second_part\n",
    "\n",
    "def insertStartStopConfigQuery(start_time, stop_time):\n",
    "    first_part = 'from(bucket: \"schempp\")|> range(start: '\n",
    "    second_part = ', stop: '\n",
    "    third_part = ')|> filter(fn: (r) => r[\"parameter\"] == \"dlMaxRetxThreshold\" or r[\"parameter\"] == \"dlPollByte\" or r[\"parameter\"] == \"dlPollPDU\" or r[\"parameter\"] == \"dlTPollRetr\" or r[\"parameter\"] == \"dlTProhib\" or r[\"parameter\"] == \"dlTReassembly\" or r[\"parameter\"] == \"ulMaxRetxThreshold\" or r[\"parameter\"] == \"ulPollByte\" or r[\"parameter\"] == \"ulPollPDU\" or r[\"parameter\"] == \"ulTPollRetr\" or r[\"parameter\"] == \"ulTProhib\" or r[\"parameter\"] == \"ulTReassembly\")|> sort()|> yield(name: \"sort\")'\n",
    "    return first_part + start_time + second_part + stop_time + third_part\n",
    "\n",
    "def insertIntervalKPIQuery(interval_time_to_add):\n",
    "    first_part = 'from(bucket: \"schempp\")|> range(start: -'\n",
    "    second_part = 's)|> filter(fn: (r) => r[\"_measurement\"] == \"kpis\")|> filter(fn: (r) => r[\"_field\"] == \"delay\" or r[\"_field\"] == \"jitter\")|> aggregateWindow(every: '\n",
    "    thrird_part = 's, fn: mean, createEmpty: false)|> yield(name: \"mean\")'\n",
    "    return first_part + str(interval_time_to_add) + second_part + str(interval_time_to_add) + thrird_part\n",
    "\n",
    "def insertStartStopKPIQuery(start_time, stop_time):\n",
    "    first_part = 'from(bucket: \"schempp\")|> range(start: '\n",
    "    second_part = ', stop: '\n",
    "    third_part = ')|> filter(fn: (r) => r[\"_measurement\"] == \"kpis\")|> filter(fn: (r) => r[\"_field\"] == \"delay\" or r[\"_field\"] == \"jitter\")|> aggregateWindow(every: '\n",
    "    fourth_part = 's, fn: mean, createEmpty: false)|> yield(name: \"mean\")'\n",
    "    return first_part + start_time + second_part + stop_time + third_part + str(config_time) + fourth_part\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an automata for the pre-learning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Define the conversion function using ast.literal_eval()\n",
    "def convert_to_string_list(string_data):\n",
    "    return ast.literal_eval(string_data)\n",
    "\n",
    "def convert_to_int_list(string_data):\n",
    "    # Handle list-like string case\n",
    "    if string_data.startswith(\"[\") and string_data.endswith(\"]\"):\n",
    "        string_data = string_data[1:-1]  # Remove brackets\n",
    "        return [int(x) for x in string_data.split(\",\")]  # Convert to integer list\n",
    "    else:\n",
    "        return [int(string_data)]  # Convert as usual\n",
    "\n",
    "def convert_to_int(string_data):\n",
    "    # Handle list-like string case\n",
    "    if string_data.startswith(\"'\") and string_data.endswith(\"'\"):\n",
    "        string_data = string_data[1:-1]  # Remove brackets\n",
    "        print(\"Covertido: \" + string_data)\n",
    "        return int(string_data)  # Convert to integer\n",
    "    else:\n",
    "        return int(string_data)  # Convert as usual\n",
    "    \n",
    "def convert_to_float(string_data):\n",
    "    return float(string_data)\n",
    "\n",
    "\n",
    "# Read the CSV file and apply the conversion function to the desired column(s)\n",
    "total_configs_df = pd.read_csv('./final_automatons_v1.15/4d/total_configs_10s_2023-06-03T12:37:00Z_2023-06-07T12:37:00Z.csv', converters={'configID': str})\n",
    "automaton_df = pd.read_csv('./final_automatons_v1.15/4d/automaton_10s_2023-06-03T12:37:00Z_2023-06-07T12:37:00Z.csv', converters={'qtyID': int, 'configID': str, 'transition': convert_to_string_list, 'slapsed_time': convert_to_int_list})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the initial configuration to the 5G Network (Nokia RAN) with the parameters selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_config_ID1_23jun_12_44h = ['t6', 'kB8', 'p24576', 'ms500', 'ms800', 'ms170', 't2', 'mB14', 'p256', 'ms120', 'ms250', 'ms55']\n",
    "baseline_config_ID2_27jun_16_16h = ['t3', 'kB6500', 'p20480', 'ms140', 'ms90', 'ms45', 't2', 'mB40', 'p256', 'ms60', 'ms130', 'ms90']\n",
    "baseline_config_ID3_19jun_11_36h = ['t32', 'kB8', 'p1024', 'ms70', 'ms100', 'ms10', 't32', 'kB25', 'p32768', 'ms30', 'ms300', 'ms120']\n",
    "baseline_config_ID4_28jun_19_51h = ['t32', 'mB40', 'p40960', 'ms40', 'ms40', 'ms180', 't32', 'kB1000', 'p1024', 'ms170', 'ms160', 'ms170']\n",
    "\n",
    "initial_config = baseline_config_ID1_23jun_12_44h\n",
    "networkReconfiguration(initial_config)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to be defined by the mobile operator (or user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qty ranges definition \n",
    "#data = {'qty': [-18, -15, -5, 1, 2, 3, 4], 'min_delay': [10000000, 0, 10000000, 0, 7000000, 0, 7000000], 'max_delay': [2000000000000, 10000000, 2000000000000, 7000000, 10000000, 7000000, 10000000], 'min_jitter': [0, 10000000, 10000000, 0, 0, 1000000, 1000000], 'max_jitter': [10000000, 2000000000000, 2000000000000, 1000000, 1000000, 10000000, 10000000]}\n",
    "data = {'qty': [-30, -18, -8, -1, 1, 2, 12, 13], 'min_delay': [12000000, 10000000, 10000000, 0, 0, 0, 7000000, 7000000], 'max_delay': [2000000000000, 12000000, 12000000, 7000000, 7000000, 7000000, 10000000, 10000000], 'min_jitter': [10000000, 8000000, 1000000, 8000000, 0, 1000000, 0, 1000000], 'max_jitter': [2000000000000, 10000000, 5000000, 10000000, 1000000, 5000000, 1000000, 5000000]}\n",
    "qty_df = pd.DataFrame(data)\n",
    "\n",
    "# Loop interval time: time (in seconds) for the operation loop\n",
    "# note that the results of KPIs will be the mean during this period; lower values result in a fine-grained automata and viceversa\n",
    "interval_time = 10\n",
    "# qty objective; it depends on the application requirements\n",
    "qty_objective = np.int64(1)\n",
    "# Time (in seconds) to consider a network configuration as suitable for reconfiguration;\n",
    "# note that higher values result in likely better configurations but probably less posibilities \n",
    "goal_time = 600\n",
    "# Number of operation cycles to be consider as stability period after a reconfiguration; it depends on the interval time\n",
    "# stability time (s) = interval_time (s) * cycles_for_stability \n",
    "cycles_for_stability = 18"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of variables and queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of variables\n",
    "old_config_id = getConfigIDhash(initial_config)\n",
    "current_cycle = 0\n",
    "objective_reached = True\n",
    "\n",
    "#Downlink and Uplink query\n",
    "dl_ul_query = insertIntervalConfigQuery(interval_time*3)\n",
    "\n",
    "#Combined query (delay and jitter)\n",
    "combined_query = insertIntervalKPIQuery(interval_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutomAdapt loop execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "\n",
    "    #Get downlink and uplink configs\n",
    "    df_dl_ul_result = query_api.query_data_frame(query=dl_ul_query)\n",
    "    #Get delay and jitter\n",
    "    df_combined_result = query_api.query_data_frame(query=combined_query)\n",
    "\n",
    "    #Combine kpis (mean)\n",
    "    df_delay = pd.DataFrame()\n",
    "    df_jitter = pd.DataFrame()\n",
    "    if (df_combined_result.empty == False):\n",
    "        df_kpis_result = df_combined_result.groupby(['_field']).mean(numeric_only=True)\n",
    "        df_delay = df_kpis_result[df_kpis_result.index == 'delay']\n",
    "        df_jitter = df_kpis_result[df_kpis_result.index == 'jitter']\n",
    "\n",
    "    #Get qty ID (just read)\n",
    "    if (df_delay.empty == False and df_jitter.empty == False):\n",
    "        read_qty_id = getqtyID(df_delay['_value'].values[0], df_jitter['_value'].values[0])\n",
    "        \n",
    "    #Get config ID (just read)\n",
    "    if (df_dl_ul_result.empty == False and len(df_dl_ul_result.index) == 12):\n",
    "        df_aux = df_dl_ul_result.drop(columns=['_start', '_stop', '_time', '_measurement', '_field', 'result', 'table', 'parameter'])\n",
    "        row = df_aux['_value'].tolist()\n",
    "        read_config_id = getConfigIDhash(row)\n",
    "        addConfig(row, read_config_id)\n",
    "    \n",
    "    #Check current state and add it to the automaton if it is not already there\n",
    "    read_state = {\"configID\": read_config_id, \"qtyID\": read_qty_id, \"transition\": [\"\"], \"slapsed_time\": [0]}\n",
    "    manageAutomatonState(read_state)\n",
    "\n",
    "    #Get current state\n",
    "    print(\"The automaton has \" + str(len(automaton_df)) + \" states\")\n",
    "    print(\"Current automaton state \" + str(current_state_id) + \" --> configID = \" + str(read_config_id) + \" / qtyID = \" + str(read_qty_id) + \"\\n\")\n",
    "    print(\"Objective qtyID = \" + str(qty_objective) + \"\\n\")\n",
    "\n",
    "    # Check the qty objective\n",
    "    if (read_qty_id != qty_objective):\n",
    "        current_cycle = current_cycle + 1\n",
    "    else:\n",
    "        current_cycle = 0\n",
    "    # Check the stability period\n",
    "    if (current_cycle >= cycles_for_stability):\n",
    "        objective_reached = False\n",
    "\n",
    "    # Check if a reconfiguration is needed due to a prediction or the qty objective has not been reached\n",
    "    if (predictionDetected(qty_objective, read_qty_id, goal_time) == True or objective_reached == False):\n",
    "        print(\"Reconfiguration needed\")\n",
    "        suitableConfigs = getSuitableConfigurations(qty_objective, goal_time)\n",
    "        if (len(suitableConfigs) > 0):\n",
    "            print(\"Suitable configurations found\")\n",
    "            for i in range(len(suitableConfigs)):\n",
    "                selectedConfig = suitableConfigs[i]\n",
    "                if ((selectedConfig[12] != current_config_id) and (reconfigAlreadyTested(selectedConfig[12]) == False)):\n",
    "                    networkReconfiguration(selectedConfig)\n",
    "                    current_cycle = 0\n",
    "                    objective_reached = True\n",
    "                    break\n",
    "            print(\"[WARNING] Any configuration has been selected...decreasing goal time\")\n",
    "            if (goal_time > 0):\n",
    "                goal_time = goal_time - 10\n",
    "            else:\n",
    "                print(\"[FATAL ERROR] No more goal time to decrease; the system is not able to reach the objective\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"[ERROR] No suitable configuration found\")\n",
    "\n",
    "    # Update the time state\n",
    "    time_state = time_state + interval_time\n",
    "    # Wait for the next loop\n",
    "    time.sleep(interval_time)\n",
    "    # Clear the output\n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the results obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_configs_df.to_csv('./final_automatons_v1.15/Reconfigurations/total_configs_Reconfigurationsv16.csv', index=False)\n",
    "automaton_df.to_csv('./final_automatons_v1.15/Reconfigurations/automaton_Reconfigurationsv16.csv', index=False)\n",
    "reconfigurations_df.to_csv('./final_automatons_v1.15/Reconfigurations/reconfigurations_Reconfigurationsv16.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create network graph to be plotted using Flourish tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_graph_df = pd.DataFrame(columns=['source', 'destination'])\n",
    "\n",
    "for i in range(len(automaton_df)-1):\n",
    "    for j in range(len(automaton_df.at[i, 'transition'])):\n",
    "        network_graph_df = network_graph_df.append({'source': i, 'destination': automaton_df.at[i, 'transition'][j].split('-')[1]}, ignore_index=True)\n",
    "\n",
    "network_graph_df['weight'] = automaton_df['slapsed_time'].apply(lambda x: sum(x))\n",
    "\n",
    "network_graph_df.to_csv('./final_automatons_v1.15/network_graph_10s_2023-06-03T12:37:00Z_2023-06-07T14:51:00Z.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
